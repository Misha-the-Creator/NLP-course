{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d903d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ced5c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение .conllu с получением токенов и pos-тэгов к ним\n",
    "\n",
    "def extract_sentences_and_pos_from_file(path):\n",
    "    sentences = []\n",
    "    pos_tags = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        current_sentence = []\n",
    "        current_pos = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            if not line:\n",
    "                if current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                    pos_tags.append(current_pos)\n",
    "                    current_sentence = []\n",
    "                    current_pos = []\n",
    "                continue\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) >= 4:\n",
    "                word = parts[1]  # слово\n",
    "                pos = parts[3]   # часть речи\n",
    "                current_sentence.append(word)\n",
    "                current_pos.append(pos)\n",
    "        if current_sentence:\n",
    "            sentences.append(current_sentence)\n",
    "            pos_tags.append(current_pos)\n",
    "    return sentences, pos_tags\n",
    "###########################################################################\n",
    "\n",
    "sentences, pos_tags = extract_sentences_and_pos_from_file('ru_syntagrus-ud-train-b.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e3fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for sent in sentences for word in sent]\n",
    "all_unique_tags = sorted(set(tag for tag_seq in pos_tags for tag in tag_seq))\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "MIN_FREQ = 2\n",
    "vocab_words = [word for word, cnt in word_counts.items() if cnt >= MIN_FREQ]\n",
    "\n",
    "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for i, word in enumerate(vocab_words, start=2):\n",
    "    word2idx[word] = i\n",
    "\n",
    "tag2idx = {tag: i for i, tag in enumerate(all_unique_tags)}\n",
    "tag2idx[\"<PAD>\"] = len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1921dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(sentences, tags, word2idx, tag2idx):\n",
    "    X, Y = [], []\n",
    "    unk_id = word2idx[\"<UNK>\"]\n",
    "    pad_tag_id = tag2idx[\"<PAD>\"]\n",
    "    \n",
    "    for sent, tag_seq in zip(sentences, tags):\n",
    "        x = [word2idx.get(word, unk_id) for word in sent]\n",
    "        y = [tag2idx[tag] for tag in tag_seq]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = encode_sentences(sentences, pos_tags, word2idx, tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f786bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 0\n",
    "for sentence in sentences:\n",
    "    if max_len < len(sentence):\n",
    "        max_len = len(sentence)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "MAX_LEN = max_len\n",
    "\n",
    "X_padded = pad_sequences(X, maxlen=MAX_LEN, padding='post', value=word2idx[\"<PAD>\"])\n",
    "y_padded = pad_sequences(Y, maxlen=MAX_LEN, padding='post', value=tag2idx[\"<PAD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63fdbdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = np.array(X_padded)\n",
    "y_final = np.array(y_padded).reshape(-1, MAX_LEN, 1)  # для sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "460d9604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759692528.279584   40542 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4620 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 22:28:53.912401: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 28ms/step - accuracy: 0.0708 - loss: 0.6603 - val_accuracy: 0.0857 - val_loss: 0.2588\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 27ms/step - accuracy: 0.0843 - loss: 0.1554 - val_accuracy: 0.0864 - val_loss: 0.2287\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - accuracy: 0.0855 - loss: 0.1144 - val_accuracy: 0.0871 - val_loss: 0.2195\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.0863 - loss: 0.0881 - val_accuracy: 0.0870 - val_loss: 0.2420\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.0869 - loss: 0.0682 - val_accuracy: 0.0865 - val_loss: 0.2628\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - accuracy: 0.0874 - loss: 0.0518 - val_accuracy: 0.0863 - val_loss: 0.2941\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.0878 - loss: 0.0387 - val_accuracy: 0.0861 - val_loss: 0.3255\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.0881 - loss: 0.0289 - val_accuracy: 0.0862 - val_loss: 0.3515\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - accuracy: 0.0883 - loss: 0.0223 - val_accuracy: 0.0858 - val_loss: 0.3935\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.0884 - loss: 0.0166 - val_accuracy: 0.0859 - val_loss: 0.4361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x761aa2106620>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, TimeDistributed\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "num_tags = len(tag2idx)\n",
    "\n",
    "inputs = Input(shape=(MAX_LEN,))\n",
    "embed = Embedding(vocab_size, 100, mask_zero=True)(inputs)\n",
    "bilstm = Bidirectional(LSTM(128, return_sequences=True))(embed)\n",
    "outputs = TimeDistributed(Dense(num_tags, activation='softmax'))(bilstm)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_final, y_final, batch_size=32, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9904a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "[('Премьер-министр', 'NOUN'), ('РФ', 'PROPN'), ('Владимир', 'PROPN'), ('Путин', 'PROPN'), ('подписал', 'VERB'), ('распоряжение', 'NOUN'), ('о', 'ADP'), ('переводе', 'NOUN'), ('Государственного', 'ADJ'), ('университета', 'NOUN'), ('-', 'PUNCT'), ('Высшей', 'ADJ'), ('школы', 'NOUN'), ('экономики', 'NOUN'), ('(', 'PUNCT'), ('ГУ-ВШЭ', 'PROPN'), (')', 'PUNCT'), ('из', 'ADP'), ('ведения', 'NOUN'), ('Минэкономразвития', 'PROPN'), ('в', 'ADP'), ('ведение', 'NOUN'), ('Правительства', 'NOUN'), ('РФ', 'PROPN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "# Возьмём ваше предложение\n",
    "test_sent = ['Премьер-министр', 'РФ', 'Владимир', 'Путин', 'подписал', 'распоряжение', 'о', 'переводе', 'Государственного', 'университета', '-', 'Высшей', 'школы', 'экономики', '(', 'ГУ-ВШЭ', ')', 'из', 'ведения', 'Минэкономразвития', 'в', 'ведение', 'Правительства', 'РФ', '.']\n",
    "\n",
    "# Преобразуем в ID\n",
    "x_test = [word2idx.get(w, word2idx[\"<UNK>\"]) for w in test_sent]\n",
    "x_test = pad_sequences([x_test], maxlen=MAX_LEN, padding='post', value=word2idx[\"<PAD>\"])\n",
    "\n",
    "# Предсказание\n",
    "pred = model.predict(x_test)\n",
    "pred_ids = pred[0].argmax(axis=-1)\n",
    "\n",
    "# Тогда создайте обратный словарь:\n",
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "\n",
    "# Обратно в теги\n",
    "pred_tags = [idx2tag[idx] for idx in pred_ids[:len(test_sent)]]\n",
    "print(list(zip(test_sent, pred_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d3e181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
